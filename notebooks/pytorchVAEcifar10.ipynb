{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jkQh6n_WtqZp","executionInfo":{"status":"ok","timestamp":1651697934410,"user_tz":240,"elapsed":802,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torchvision.datasets import MNIST, FashionMNIST, CIFAR10, STL10\n","import os\n","import pickle\n","import zipfile\n","import datetime\n","import torch.utils.data as tud"]},{"cell_type":"code","source":["torch.manual_seed(0)\n","np.random.seed(0)"],"metadata":{"id":"9rnOt6_PPj9_","executionInfo":{"status":"ok","timestamp":1651697934411,"user_tz":240,"elapsed":3,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c0JndQs0tqZt"},"source":["# Data Preparation:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LY2_lV6_tqZu","executionInfo":{"status":"ok","timestamp":1651697934411,"user_tz":240,"elapsed":2,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["mean,std = (0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)\n","data_transform = transforms.Compose([ transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean,std),\n","                transforms.Resize((96,96))\n","        ])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQKYtenytqZw","outputId":"f17f3902-0a82-4c77-998b-e8a91026506d","executionInfo":{"status":"ok","timestamp":1651697936138,"user_tz":240,"elapsed":1729,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["train = CIFAR10(root='./data', train=True,download=True, transform=data_transform)\n","test = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=data_transform)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9acPhfitqZ1","outputId":"68cf7596-2814-4303-c458-75c770abb8be","executionInfo":{"status":"ok","timestamp":1651697936139,"user_tz":240,"elapsed":9,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset CIFAR10\n","    Number of datapoints: 10000\n","    Root location: ./data\n","    Split: Test\n","    StandardTransform\n","Transform: Compose(\n","               RandomHorizontalFlip(p=0.5)\n","               ToTensor()\n","               Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761))\n","               Resize(size=(96, 96), interpolation=bilinear, max_size=None, antialias=None)\n","           )"]},"metadata":{},"execution_count":5}],"source":["test"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"sdmz10AjtqZ4","executionInfo":{"status":"ok","timestamp":1651697936139,"user_tz":240,"elapsed":5,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train, batch_size=50000, shuffle=False, num_workers=0)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VeW3C0ZEtqZ5","executionInfo":{"status":"ok","timestamp":1651697961745,"user_tz":240,"elapsed":25610,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["data, labels= next(iter(train_loader))"]},{"cell_type":"markdown","metadata":{"id":"ZTeJyRRXtFsr"},"source":["## Using 500 labled data for 1% and 5000 labeled data for 10% case"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"vPYd4ulQtqZ7","executionInfo":{"status":"ok","timestamp":1651697961746,"user_tz":240,"elapsed":29,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#keep 2500 as labeled data\n","np.random.seed(5)\n","labeled_ind = np.random.choice(50000,7000, replace = False)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"r7_D07TjtqZ9","executionInfo":{"status":"ok","timestamp":1651697961747,"user_tz":240,"elapsed":29,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["unlabeled_ind = np.setdiff1d(list(range(50000)), labeled_ind)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"11xCiYjQtqZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651697961747,"user_tz":240,"elapsed":29,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"07e99903-c5b7-4beb-905f-8682d54a3eca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(43000,)"]},"metadata":{},"execution_count":10}],"source":["unlabeled_ind.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"iQ4TEQOttqaC","executionInfo":{"status":"ok","timestamp":1651697961748,"user_tz":240,"elapsed":26,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["labels = labels.numpy()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AUKB2kQjtqaE","executionInfo":{"status":"ok","timestamp":1651697961748,"user_tz":240,"elapsed":26,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#unlabeled data coded as 10\n","np.put(labels,list(unlabeled_ind),10)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lDso6h9-tqaH","executionInfo":{"status":"ok","timestamp":1651697961748,"user_tz":240,"elapsed":26,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#make 0.3 of the labeled data dev set, dev set is made sure to have balanced labels\n","np.random.seed(5)\n","dev_ind = labeled_ind[np.random.choice(7000,2000, replace = False)]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"6EBDbgcctqaI","executionInfo":{"status":"ok","timestamp":1651697961748,"user_tz":240,"elapsed":26,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["train_ind = np.setdiff1d(list(range(50000)), dev_ind)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-Vp0l9ytqaK","outputId":"ef1fadbc-66b7-4ac9-bbb7-11aceed0e3bd","executionInfo":{"status":"ok","timestamp":1651697961749,"user_tz":240,"elapsed":27,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2000, 48000)"]},"metadata":{},"execution_count":15}],"source":["#450 labeled data for dev set, 1050 labeled data + 6500 unlabeled data for training set\n","len(dev_ind), len(train_ind)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"lGibOIxAtqaN","executionInfo":{"status":"ok","timestamp":1651697961749,"user_tz":240,"elapsed":22,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#prepare dataloader for pytorch\n","class TorchInputData(tud.Dataset):\n","    \"\"\"\n","    A simple inheretance of torch.DataSet to enable using our customized DogBreed dataset in torch\n","    \"\"\"\n","    def __init__(self, X, Y, transform=None):\n","        \"\"\"\n","        X: a list of numpy images \n","        Y: a list of labels coded using 0-9 \n","        \"\"\"        \n","        self.X = X\n","        self.Y = Y \n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        x = self.X[idx]\n","        y = self.Y[idx]\n","\n","        return x, y"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"AGNVrPRTtqaP","executionInfo":{"status":"ok","timestamp":1651697961749,"user_tz":240,"elapsed":22,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["images_train = [data[i] for i in train_ind]\n","trainset = TorchInputData(images_train, labels[train_ind])\n","train_loader = tud.DataLoader(trainset, batch_size=100, shuffle=True)"]},{"cell_type":"code","source":["len(trainset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbYfDTQ-jXIK","executionInfo":{"status":"ok","timestamp":1651697961750,"user_tz":240,"elapsed":23,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"c569d1bc-5bda-4e09-c2c0-d6904ba7b626"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["48000"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"lcjD5NzytqaS","executionInfo":{"status":"ok","timestamp":1651697961750,"user_tz":240,"elapsed":20,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["images_dev = [data[i] for i in dev_ind]\n","devset = TorchInputData(images_dev, labels[dev_ind])\n","dev_loader = tud.DataLoader(devset, batch_size=100, shuffle=True)"]},{"cell_type":"code","source":["len(devset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2dmmsNIjbU3","executionInfo":{"status":"ok","timestamp":1651697961750,"user_tz":240,"elapsed":20,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"3077d8cd-73b5-4f25-940b-3c9fb29acba4"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"8_LunrTitFsv"},"source":["# M2 Model:"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"MRJzKo-qtqaV","executionInfo":{"status":"ok","timestamp":1651697961751,"user_tz":240,"elapsed":18,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#import nn.module for M2 and CNN classifier\n","from m2_stl10_cuda_clipped_logvar import M2,Classifier"]},{"cell_type":"code","source":["\n","from torch.nn.utils import weight_norm\n","\n","class Discriminator(nn.Module):\n","        \"\"\"docstring for Discriminator\"\"\"\n","        def __init__(self,num_classes):\n","            super(Discriminator, self).__init__()\n","            self.net = nn.Sequential(\n","                    weight_norm(nn.Conv2d(3,3,3,stride=3,padding=1)),\n","                    nn.Dropout(.2),\n","                    weight_norm(nn.Conv2d(3,96,3,stride=1,padding=1)),\n","                    nn.LeakyReLU(),\n","                    weight_norm(nn.Conv2d(96,96,3,stride=1,padding=1)),\n","                    nn.LeakyReLU(),\n","                    weight_norm(nn.Conv2d(96,96,3,stride=2,padding=1)),\n","                    nn.LeakyReLU(),\n","\n","                    nn.Dropout(.5),\n","                    weight_norm(nn.Conv2d(96,192,3,stride=1,padding=1)),\n","                    nn.LeakyReLU(),\n","                    weight_norm(nn.Conv2d(192,192,3,stride=1,padding=1)),\n","                    nn.LeakyReLU(),\n","                    weight_norm(nn.Conv2d(192,192,3,stride=2,padding=1)),\n","                    nn.LeakyReLU(),\n","                    \n","                    nn.Dropout(.5),\n","                    weight_norm(nn.Conv2d(192,192,3,stride=1,padding=0)),\n","                    nn.LeakyReLU(),\n","                    weight_norm(nn.Conv2d(192,192,1,stride=1,padding=0)),\n","                    nn.LeakyReLU(),\n","                    weight_norm(nn.Conv2d(192,192,1,stride=1,padding=0)),\n","                    nn.LeakyReLU(),\n","\n","                    # nn.AvgPool2d(6,stride=1),\n","                    nn.AdaptiveAvgPool2d(1),\n","                    nn.Flatten()\n","                )\n","\n","            self.fc = weight_norm(nn.Linear(192,num_classes))\n","            \n","        def forward(self,x):\n","            inter_layer = self.net(x)\n","            logits = F.log_softmax(self.fc(inter_layer),dim=1)\n","            return logits\n","lr = 0.01\n","num_epochs = 50\n","\n","classifier = Discriminator(10)\n"],"metadata":{"id":"Q8XS-J05RoMc","executionInfo":{"status":"ok","timestamp":1651697961985,"user_tz":240,"elapsed":15,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["'''\n","from torchvision import models\n","classifier = models.resnet50(pretrained=False)\n","classifier.fc = nn.Linear(2048, 10)\n","\n","gpu_boole = torch.cuda.is_available()\n","if gpu_boole:\n","  classifier.cuda()\n","  '''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"R8lgXvP1fra-","executionInfo":{"status":"ok","timestamp":1651697961985,"user_tz":240,"elapsed":15,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"0bd8e01b-27a0-441c-ed75-4635f1b9073e"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfrom torchvision import models\\nclassifier = models.resnet50(pretrained=False)\\nclassifier.fc = nn.Linear(2048, 10)\\n\\ngpu_boole = torch.cuda.is_available()\\nif gpu_boole:\\n  classifier.cuda()\\n  '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["#for param in classifier.parameters():\n","#    param.requires_grad = False"],"metadata":{"id":"7eXqb2FTr8Ld","executionInfo":{"status":"ok","timestamp":1651697961986,"user_tz":240,"elapsed":14,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#classifier.fc.requires_grad=True"],"metadata":{"id":"8N1K4OC7sLl6","executionInfo":{"status":"ok","timestamp":1651697961986,"user_tz":240,"elapsed":14,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"a9Mkg3BatqaX","executionInfo":{"status":"ok","timestamp":1651697961986,"user_tz":240,"elapsed":14,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#classifier = Classifier(image_reso = 96, filter_size = 5, dropout_rate = 0.2)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"KI8aHlvUtqaY","executionInfo":{"status":"ok","timestamp":1651697964809,"user_tz":240,"elapsed":2837,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["m2 = M2(latent_features = 128, classifier = classifier, path = \"m2_stl10_0.1_50epoch_5.pth\")"]},{"cell_type":"markdown","metadata":{"id":"hpLeyXNdtFsx"},"source":["### Structure of the M2 model: a convolutional variational autoencoder and a CNN classifier"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5Vl3MFKtFsx","executionInfo":{"status":"ok","timestamp":1651697964810,"user_tz":240,"elapsed":13,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"e5c40b81-aabe-49b4-d2af-d27e2dbb1f01"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["M2_base(\n","  (encoder): Encoder(\n","    (bottle): EncoderModule(\n","      (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (m1): EncoderModule(\n","      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (m2): EncoderModule(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n","      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (m3): EncoderModule(\n","      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n","      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (fc1): Linear(in_features=9226, out_features=128, bias=True)\n","  (fc2): Linear(in_features=9226, out_features=128, bias=True)\n","  (fc3): Linear(in_features=138, out_features=9216, bias=True)\n","  (decoder): Decoder(\n","    (m1): DecoderModule(\n","      (convt): ConvTranspose2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activation): ReLU(inplace=True)\n","    )\n","    (m2): DecoderModule(\n","      (convt): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(4, 4))\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activation): ReLU(inplace=True)\n","    )\n","    (m3): DecoderModule(\n","      (convt): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(4, 4))\n","      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activation): ReLU(inplace=True)\n","    )\n","    (bottle): DecoderModule(\n","      (convt): ConvTranspose2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activation): Sigmoid()\n","    )\n","  )\n","  (classifier): Discriminator(\n","    (net): Sequential(\n","      (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): LeakyReLU(negative_slope=0.01)\n","      (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): LeakyReLU(negative_slope=0.01)\n","      (6): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (7): LeakyReLU(negative_slope=0.01)\n","      (8): Dropout(p=0.5, inplace=False)\n","      (9): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (10): LeakyReLU(negative_slope=0.01)\n","      (11): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (12): LeakyReLU(negative_slope=0.01)\n","      (13): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (14): LeakyReLU(negative_slope=0.01)\n","      (15): Dropout(p=0.5, inplace=False)\n","      (16): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))\n","      (17): LeakyReLU(negative_slope=0.01)\n","      (18): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","      (19): LeakyReLU(negative_slope=0.01)\n","      (20): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","      (21): LeakyReLU(negative_slope=0.01)\n","      (22): AdaptiveAvgPool2d(output_size=1)\n","      (23): Flatten(start_dim=1, end_dim=-1)\n","    )\n","    (fc): Linear(in_features=192, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":28}],"source":["m2.model"]},{"cell_type":"markdown","metadata":{"id":"ph9ZLRdctFsx"},"source":["### Training the M2 model for 50 epochs:"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Ek1KOmSwtqaa","executionInfo":{"status":"ok","timestamp":1651697964812,"user_tz":240,"elapsed":8,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#set alpha, hyperparameter for weighing the classifier loss\n","alpha = 0.1*len(train_loader.dataset)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2kZhMjMtqab","outputId":"b6026e45-578b-435f-fd51-e4977dae7fc5","executionInfo":{"status":"ok","timestamp":1651701305389,"user_tz":240,"elapsed":3340585,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 480 Loss: 47512.171875\n","50 480 Loss: 19478.032686\n","100 480 Loss: 12723.287719\n","150 480 Loss: 8947.018377\n","200 480 Loss: 6147.081917\n","250 480 Loss: 3009.350109\n","300 480 Loss: -919.160390\n","350 480 Loss: -5604.619782\n","400 480 Loss: -10392.329972\n","450 480 Loss: -14760.652102\n","Epoch: 1, train loss: -17088.9885, training accuracy 0.0972, dev set accuracy 0.0975\n","0 480 Loss: -54450.218750\n","50 480 Loss: -58579.954082\n","100 480 Loss: -62021.118019\n","150 480 Loss: -63137.539127\n","200 480 Loss: -65725.385465\n","250 480 Loss: -67540.162203\n","300 480 Loss: -70006.230008\n","350 480 Loss: -72063.844045\n","400 480 Loss: -74535.582523\n","450 480 Loss: -76866.551894\n","Epoch: 2, train loss: -78273.5599, training accuracy 0.1076, dev set accuracy 0.1730\n","0 480 Loss: -70897.210938\n","50 480 Loss: -105931.836320\n","100 480 Loss: -106395.759708\n","150 480 Loss: -106113.709204\n","200 480 Loss: -107258.172944\n","250 480 Loss: -109365.369164\n","300 480 Loss: -111597.745081\n","350 480 Loss: -113801.050069\n","400 480 Loss: -117369.156143\n","450 480 Loss: -119134.012273\n","Epoch: 3, train loss: -119998.3275, training accuracy 0.1906, dev set accuracy 0.1970\n","0 480 Loss: -217011.062500\n","50 480 Loss: -142548.501379\n","100 480 Loss: -143226.631188\n","150 480 Loss: -144469.489549\n","200 480 Loss: -144635.611901\n","250 480 Loss: -147639.695188\n","300 480 Loss: -149609.247742\n","350 480 Loss: -151765.351473\n","400 480 Loss: -154733.911043\n","450 480 Loss: -156690.971522\n","Epoch: 4, train loss: -157661.2895, training accuracy 0.2016, dev set accuracy 0.2150\n","0 480 Loss: -229823.296875\n","50 480 Loss: -177543.233303\n","100 480 Loss: -180761.504796\n","150 480 Loss: -183321.657699\n","200 480 Loss: -185059.878109\n","250 480 Loss: -186856.929221\n","300 480 Loss: -186565.831655\n","350 480 Loss: -190491.289797\n","400 480 Loss: -192187.983674\n","450 480 Loss: -193206.845655\n","Epoch: 5, train loss: -194745.7948, training accuracy 0.2356, dev set accuracy 0.2595\n","0 480 Loss: -177940.343750\n","50 480 Loss: -217516.103860\n","100 480 Loss: -217042.113243\n","150 480 Loss: -220752.431602\n","200 480 Loss: -220941.829136\n","250 480 Loss: -223347.242966\n","300 480 Loss: -227677.026267\n","350 480 Loss: -227832.437901\n","400 480 Loss: -229838.736791\n","450 480 Loss: -230913.691727\n","Epoch: 6, train loss: -232099.0194, training accuracy 0.2666, dev set accuracy 0.2860\n","0 480 Loss: -260176.843750\n","50 480 Loss: -264255.296262\n","100 480 Loss: -260889.719214\n","150 480 Loss: -265256.431291\n","200 480 Loss: -261921.355410\n","250 480 Loss: -262341.885832\n","300 480 Loss: -264810.875415\n","350 480 Loss: -265428.089476\n","400 480 Loss: -267637.033354\n","450 480 Loss: -269831.482816\n","Epoch: 7, train loss: -270027.8232, training accuracy 0.2984, dev set accuracy 0.3310\n","0 480 Loss: -231815.468750\n","50 480 Loss: -281745.256127\n","100 480 Loss: -281477.081064\n","150 480 Loss: -283998.964611\n","200 480 Loss: -291918.925218\n","250 480 Loss: -296944.963645\n","300 480 Loss: -296798.108804\n","350 480 Loss: -298924.953481\n","400 480 Loss: -302869.522600\n","450 480 Loss: -304394.019713\n","Epoch: 8, train loss: -305975.0349, training accuracy 0.3276, dev set accuracy 0.3160\n","0 480 Loss: -258579.437500\n","50 480 Loss: -324122.812194\n","100 480 Loss: -320891.207766\n","150 480 Loss: -331282.205815\n","200 480 Loss: -333443.668532\n","250 480 Loss: -332554.612052\n","300 480 Loss: -337717.897996\n","350 480 Loss: -338799.011930\n","400 480 Loss: -340357.273145\n","450 480 Loss: -341840.151885\n","Epoch: 9, train loss: -341382.6572, training accuracy 0.3368, dev set accuracy 0.3340\n","0 480 Loss: -509956.968750\n","50 480 Loss: -351862.471814\n","100 480 Loss: -359801.476795\n","150 480 Loss: -362084.111548\n","200 480 Loss: -362611.854011\n","250 480 Loss: -364394.931773\n","300 480 Loss: -366490.815822\n","350 480 Loss: -369877.347044\n","400 480 Loss: -373073.856608\n","450 480 Loss: -374666.900083\n","Epoch: 10, train loss: -376803.0934, training accuracy 0.3470, dev set accuracy 0.3360\n","0 480 Loss: -377821.437500\n","50 480 Loss: -395540.299020\n","100 480 Loss: -402403.297339\n","150 480 Loss: -397308.760969\n","200 480 Loss: -400045.292444\n","250 480 Loss: -402524.635956\n","300 480 Loss: -400593.745172\n","350 480 Loss: -402572.527021\n","400 480 Loss: -403179.569475\n","450 480 Loss: -404171.479040\n","Epoch: 11, train loss: -406072.3707, training accuracy 0.3472, dev set accuracy 0.3250\n","0 480 Loss: -572114.062500\n","50 480 Loss: -425141.596814\n","100 480 Loss: -430806.091275\n","150 480 Loss: -433283.996896\n","200 480 Loss: -436333.976990\n","250 480 Loss: -434003.937749\n","300 480 Loss: -431105.819352\n","350 480 Loss: -432738.238960\n","400 480 Loss: -433327.120636\n","450 480 Loss: -434877.110033\n","Epoch: 12, train loss: -435916.1639, training accuracy 0.3612, dev set accuracy 0.3670\n","0 480 Loss: -560214.312500\n","50 480 Loss: -438582.778799\n","100 480 Loss: -445823.881807\n","150 480 Loss: -448343.129553\n","200 480 Loss: -451608.037002\n","250 480 Loss: -456621.111056\n","300 480 Loss: -458901.411649\n","350 480 Loss: -459668.121795\n","400 480 Loss: -462245.320527\n","450 480 Loss: -463065.332040\n","Epoch: 13, train loss: -463785.1333, training accuracy 0.3662, dev set accuracy 0.3965\n","0 480 Loss: -479355.625000\n","50 480 Loss: -474286.436887\n","100 480 Loss: -476954.759901\n","150 480 Loss: -480138.590853\n","200 480 Loss: -480447.532183\n","250 480 Loss: -485248.241285\n","300 480 Loss: -487239.402512\n","350 480 Loss: -488082.653668\n","400 480 Loss: -490150.988155\n","450 480 Loss: -491610.371674\n","Epoch: 14, train loss: -492905.7641, training accuracy 0.3870, dev set accuracy 0.3665\n","0 480 Loss: -413673.812500\n","50 480 Loss: -501790.007353\n","100 480 Loss: -506642.883354\n","150 480 Loss: -506192.689776\n","200 480 Loss: -505838.690299\n","250 480 Loss: -507831.254856\n","300 480 Loss: -512299.291009\n","350 480 Loss: -512676.303953\n","400 480 Loss: -515378.215711\n","450 480 Loss: -515957.498060\n","Epoch: 15, train loss: -517259.4658, training accuracy 0.3918, dev set accuracy 0.3905\n","0 480 Loss: -461162.812500\n","50 480 Loss: -523660.329044\n","100 480 Loss: -528520.387376\n","150 480 Loss: -528024.556498\n","200 480 Loss: -528949.475124\n","250 480 Loss: -533239.141310\n","300 480 Loss: -533159.810735\n","350 480 Loss: -534600.622151\n","400 480 Loss: -535202.156172\n","450 480 Loss: -537424.839800\n","Epoch: 16, train loss: -537394.9362, training accuracy 0.3960, dev set accuracy 0.3930\n","0 480 Loss: -595320.437500\n","50 480 Loss: -557260.283701\n","100 480 Loss: -565984.618193\n","150 480 Loss: -557493.955505\n","200 480 Loss: -559320.540734\n","250 480 Loss: -556664.827565\n","300 480 Loss: -557702.357662\n","350 480 Loss: -561585.771635\n","400 480 Loss: -559901.364713\n","450 480 Loss: -560349.419069\n","Epoch: 17, train loss: -560914.6827, training accuracy 0.4150, dev set accuracy 0.4025\n","0 480 Loss: -484439.406250\n","50 480 Loss: -577304.891544\n","100 480 Loss: -585405.283106\n","150 480 Loss: -583519.025455\n","200 480 Loss: -584973.196673\n","250 480 Loss: -582388.558516\n","300 480 Loss: -581083.563538\n","350 480 Loss: -580653.978454\n","400 480 Loss: -580907.959554\n","450 480 Loss: -582521.656596\n","Epoch: 18, train loss: -582373.9285, training accuracy 0.4256, dev set accuracy 0.3960\n","0 480 Loss: -505918.062500\n","50 480 Loss: -590269.724265\n","100 480 Loss: -588742.613552\n","150 480 Loss: -592920.974338\n","200 480 Loss: -600290.610075\n","250 480 Loss: -602039.083416\n","300 480 Loss: -597001.879880\n","350 480 Loss: -598557.222222\n","400 480 Loss: -601526.679473\n","450 480 Loss: -602783.158606\n","Epoch: 19, train loss: -602669.7615, training accuracy 0.4368, dev set accuracy 0.4250\n","0 480 Loss: -595842.500000\n","50 480 Loss: -607803.039828\n","100 480 Loss: -614882.547339\n","200 480 Loss: -623265.079136\n","250 480 Loss: -623669.943725\n","300 480 Loss: -620686.641507\n","350 480 Loss: -619412.374466\n","400 480 Loss: -619084.948410\n","450 480 Loss: -617160.215078\n","Epoch: 20, train loss: -617406.1600, training accuracy 0.4378, dev set accuracy 0.4200\n","0 480 Loss: -587660.000000\n","50 480 Loss: -622949.017157\n","100 480 Loss: -621775.279703\n","150 480 Loss: -632387.279801\n","200 480 Loss: -631696.768812\n","250 480 Loss: -632762.470991\n","300 480 Loss: -632591.533949\n","350 480 Loss: -632879.812856\n","400 480 Loss: -635532.903756\n","450 480 Loss: -636701.407636\n","Epoch: 21, train loss: -636762.2707, training accuracy 0.4434, dev set accuracy 0.4215\n","0 480 Loss: -788024.687500\n","50 480 Loss: -639013.968137\n","100 480 Loss: -641465.970606\n","150 480 Loss: -646103.878104\n","200 480 Loss: -647000.485852\n","250 480 Loss: -651680.456300\n","300 480 Loss: -651788.767130\n","350 480 Loss: -652686.220442\n","400 480 Loss: -652091.779068\n","450 480 Loss: -654296.485172\n","Epoch: 22, train loss: -655319.4513, training accuracy 0.4524, dev set accuracy 0.4025\n","0 480 Loss: -663871.125000\n","50 480 Loss: -672140.272059\n","100 480 Loss: -653523.288985\n","150 480 Loss: -667010.849545\n","200 480 Loss: -665501.397544\n","250 480 Loss: -667663.600722\n","300 480 Loss: -670102.200062\n","350 480 Loss: -670848.122151\n","400 480 Loss: -672652.066864\n","450 480 Loss: -672139.928562\n","Epoch: 23, train loss: -672218.7667, training accuracy 0.4698, dev set accuracy 0.4585\n","0 480 Loss: -677514.750000\n","50 480 Loss: -688311.506127\n","100 480 Loss: -677655.092203\n","150 480 Loss: -679821.338990\n","200 480 Loss: -682429.044154\n","250 480 Loss: -685953.718003\n","300 480 Loss: -685378.599772\n","350 480 Loss: -685981.954683\n","400 480 Loss: -689743.385053\n","450 480 Loss: -691388.944637\n","Epoch: 24, train loss: -690176.5523, training accuracy 0.4854, dev set accuracy 0.4380\n","0 480 Loss: -619243.437500\n","50 480 Loss: -711249.183824\n","100 480 Loss: -708096.475248\n","150 480 Loss: -706057.263245\n","200 480 Loss: -703750.189366\n","250 480 Loss: -701902.903884\n","300 480 Loss: -703250.669228\n","350 480 Loss: -704379.878561\n","400 480 Loss: -703179.896820\n","450 480 Loss: -705043.323309\n","Epoch: 25, train loss: -704035.3326, training accuracy 0.4858, dev set accuracy 0.4710\n","0 480 Loss: -781274.000000\n","50 480 Loss: -714278.937500\n","100 480 Loss: -707474.324567\n","150 480 Loss: -707749.108237\n","200 480 Loss: -709227.973103\n","250 480 Loss: -715368.578561\n","300 480 Loss: -719615.993459\n","350 480 Loss: -719734.550303\n","400 480 Loss: -719493.977790\n","450 480 Loss: -720949.218750\n","Epoch: 26, train loss: -722112.8174, training accuracy 0.5110, dev set accuracy 0.4615\n","0 480 Loss: -758037.000000\n","50 480 Loss: -726966.839461\n","100 480 Loss: -729078.777847\n","150 480 Loss: -730185.978477\n","200 480 Loss: -729946.384017\n","250 480 Loss: -730035.752490\n","300 480 Loss: -731421.204942\n","350 480 Loss: -734485.016738\n","400 480 Loss: -738007.258416\n","450 480 Loss: -739378.374723\n","Epoch: 27, train loss: -739591.9837, training accuracy 0.5166, dev set accuracy 0.4185\n","0 480 Loss: -503388.031250\n","50 480 Loss: -746485.092525\n","100 480 Loss: -739626.412438\n","150 480 Loss: -742886.709230\n","200 480 Loss: -750398.015392\n","250 480 Loss: -749364.726718\n","300 480 Loss: -749774.410610\n","350 480 Loss: -756070.002404\n","400 480 Loss: -757535.106842\n","450 480 Loss: -759897.952397\n","Epoch: 28, train loss: -757977.6779, training accuracy 0.5218, dev set accuracy 0.4710\n","0 480 Loss: -869043.750000\n","50 480 Loss: -769781.485294\n","100 480 Loss: -772358.443688\n","150 480 Loss: -775186.709851\n","200 480 Loss: -779111.258706\n","250 480 Loss: -778493.934014\n","300 480 Loss: -776061.939576\n","350 480 Loss: -777012.955128\n","400 480 Loss: -777007.463996\n","450 480 Loss: -776788.219651\n","Epoch: 29, train loss: -778157.0896, training accuracy 0.5396, dev set accuracy 0.4775\n","0 480 Loss: -852396.250000\n","50 480 Loss: -794769.490196\n","100 480 Loss: -803448.681002\n","150 480 Loss: -797470.080919\n","200 480 Loss: -797458.348414\n","250 480 Loss: -794288.483192\n","300 480 Loss: -789941.084199\n","350 480 Loss: -794321.741008\n","400 480 Loss: -792340.478257\n","450 480 Loss: -793462.209881\n","Epoch: 30, train loss: -793554.3973, training accuracy 0.5398, dev set accuracy 0.4725\n","0 480 Loss: -863393.125000\n","50 480 Loss: -801256.137255\n","100 480 Loss: -808382.241955\n","150 480 Loss: -809122.766142\n","200 480 Loss: -810711.369403\n","250 480 Loss: -811758.996016\n","300 480 Loss: -816124.836794\n","350 480 Loss: -814474.856125\n","400 480 Loss: -813718.574501\n","450 480 Loss: -815363.746674\n","Epoch: 31, train loss: -815255.8424, training accuracy 0.5542, dev set accuracy 0.4455\n","0 480 Loss: -944665.187500\n","50 480 Loss: -848346.362745\n","100 480 Loss: -844964.993193\n","150 480 Loss: -847208.930877\n","200 480 Loss: -843778.106654\n","250 480 Loss: -840785.001245\n","300 480 Loss: -841138.204111\n","350 480 Loss: -838560.539708\n","400 480 Loss: -838681.689838\n","450 480 Loss: -838658.528963\n","Epoch: 32, train loss: -839261.9410, training accuracy 0.5592, dev set accuracy 0.4610\n","0 480 Loss: -678278.000000\n","50 480 Loss: -862020.872549\n","100 480 Loss: -853845.303837\n","150 480 Loss: -865738.345199\n","200 480 Loss: -862198.482276\n","250 480 Loss: -861528.565737\n","300 480 Loss: -861744.875415\n","350 480 Loss: -861289.321225\n","400 480 Loss: -860658.725530\n","450 480 Loss: -860885.333564\n","Epoch: 33, train loss: -862676.0891, training accuracy 0.5648, dev set accuracy 0.4625\n","0 480 Loss: -826937.750000\n","50 480 Loss: -870406.552696\n","100 480 Loss: -884813.663985\n","150 480 Loss: -882700.406457\n","200 480 Loss: -883416.088930\n","250 480 Loss: -886846.016932\n","300 480 Loss: -887781.017650\n","350 480 Loss: -888045.808939\n","400 480 Loss: -889919.412562\n","450 480 Loss: -889945.475194\n","Epoch: 34, train loss: -889578.7453, training accuracy 0.5780, dev set accuracy 0.4915\n","0 480 Loss: -627740.125000\n","50 480 Loss: -897209.681373\n","100 480 Loss: -900547.735149\n","150 480 Loss: -903710.810017\n","200 480 Loss: -907900.608209\n","250 480 Loss: -903771.683516\n","300 480 Loss: -904195.887666\n","350 480 Loss: -908860.317486\n","400 480 Loss: -910492.359414\n","450 480 Loss: -912556.730044\n","Epoch: 35, train loss: -913632.8594, training accuracy 0.5854, dev set accuracy 0.4905\n","0 480 Loss: -789823.375000\n","50 480 Loss: -927702.199755\n","100 480 Loss: -933311.732673\n","150 480 Loss: -932035.085679\n","200 480 Loss: -928306.993470\n","250 480 Loss: -932291.944223\n","300 480 Loss: -933623.193937\n","350 480 Loss: -937884.528846\n","400 480 Loss: -938867.550343\n","450 480 Loss: -939047.785615\n","Epoch: 36, train loss: -939513.6215, training accuracy 0.5890, dev set accuracy 0.4955\n","0 480 Loss: -823381.750000\n","50 480 Loss: -935783.394608\n","100 480 Loss: -932274.152228\n","150 480 Loss: -943320.837748\n","200 480 Loss: -948678.667289\n","250 480 Loss: -952881.160857\n","300 480 Loss: -952467.619601\n","350 480 Loss: -957244.714922\n","400 480 Loss: -957741.627805\n","450 480 Loss: -962317.357400\n","Epoch: 37, train loss: -963792.0734, training accuracy 0.6118, dev set accuracy 0.4995\n","0 480 Loss: -979095.875000\n","50 480 Loss: -968147.736520\n","100 480 Loss: -979553.657178\n","150 480 Loss: -982946.387417\n","200 480 Loss: -981764.859764\n","250 480 Loss: -979603.008466\n","300 480 Loss: -981966.572051\n","350 480 Loss: -981022.459936\n","400 480 Loss: -983766.610661\n","450 480 Loss: -983979.645649\n","Epoch: 38, train loss: -984945.9143, training accuracy 0.6220, dev set accuracy 0.5045\n","0 480 Loss: -994075.500000\n","50 480 Loss: -992126.128676\n","100 480 Loss: -996886.538985\n","150 480 Loss: -996783.250828\n","200 480 Loss: -997051.864117\n","250 480 Loss: -1002961.427540\n","300 480 Loss: -1000821.773879\n","350 480 Loss: -1004378.263177\n","400 480 Loss: -1004525.435630\n","450 480 Loss: -1005153.288664\n","Epoch: 39, train loss: -1004968.6324, training accuracy 0.6258, dev set accuracy 0.4985\n","0 480 Loss: -1044368.875000\n","50 480 Loss: -1023610.665441\n","100 480 Loss: -1017374.988861\n","150 480 Loss: -1020022.549669\n","200 480 Loss: -1020848.280473\n","250 480 Loss: -1017740.722859\n","300 480 Loss: -1016265.131022\n","350 480 Loss: -1018123.514779\n","400 480 Loss: -1014893.973036\n","450 480 Loss: -1018540.688331\n","Epoch: 40, train loss: -1017216.7991, training accuracy 0.6388, dev set accuracy 0.4905\n","0 480 Loss: -1137685.750000\n","50 480 Loss: -1023813.039216\n","100 480 Loss: -1039331.879332\n","150 480 Loss: -1043612.806705\n","200 480 Loss: -1037319.024565\n","250 480 Loss: -1030294.379482\n","300 480 Loss: -1025650.531354\n","350 480 Loss: -1023633.313568\n","400 480 Loss: -1025100.951216\n","450 480 Loss: -1026467.713276\n","Epoch: 41, train loss: -1026495.0375, training accuracy 0.6398, dev set accuracy 0.4950\n","0 480 Loss: -1045249.000000\n","50 480 Loss: -1031615.881127\n","100 480 Loss: -1031950.827970\n","150 480 Loss: -1036411.391970\n","200 480 Loss: -1039738.123134\n","250 480 Loss: -1038756.711653\n","300 480 Loss: -1038836.587209\n","350 480 Loss: -1035615.187856\n","400 480 Loss: -1037471.137469\n","450 480 Loss: -1039402.455931\n","Epoch: 42, train loss: -1040067.1004, training accuracy 0.6506, dev set accuracy 0.4945\n","0 480 Loss: -1097755.250000\n","50 480 Loss: -1052379.454657\n","100 480 Loss: -1040892.504332\n","150 480 Loss: -1041906.386589\n","200 480 Loss: -1042337.796953\n","250 480 Loss: -1042357.534612\n","300 480 Loss: -1040845.980897\n","350 480 Loss: -1043516.784722\n","400 480 Loss: -1046346.046914\n","450 480 Loss: -1049501.283537\n","Epoch: 43, train loss: -1049844.0750, training accuracy 0.6688, dev set accuracy 0.5105\n","0 480 Loss: -1114060.000000\n","50 480 Loss: -1049880.893382\n","100 480 Loss: -1054617.994431\n","150 480 Loss: -1061108.709851\n","200 480 Loss: -1060899.090796\n","250 480 Loss: -1059940.239542\n","300 480 Loss: -1057405.330357\n","350 480 Loss: -1056107.228632\n","400 480 Loss: -1055423.881390\n","450 480 Loss: -1053237.811114\n","Epoch: 44, train loss: -1054533.1839, training accuracy 0.6700, dev set accuracy 0.5055\n","0 480 Loss: -1053444.250000\n","50 480 Loss: -1040497.954657\n","100 480 Loss: -1050950.978342\n","150 480 Loss: -1052731.031871\n","200 480 Loss: -1049718.163557\n","250 480 Loss: -1054085.140189\n","300 480 Loss: -1058492.078696\n","350 480 Loss: -1059269.419872\n","400 480 Loss: -1060969.959788\n","450 480 Loss: -1061572.643154\n","Epoch: 45, train loss: -1061577.9164, training accuracy 0.6752, dev set accuracy 0.5000\n","0 480 Loss: -1135194.500000\n","50 480 Loss: -1084045.901961\n","100 480 Loss: -1065938.767946\n","150 480 Loss: -1061414.238411\n","200 480 Loss: -1066085.453669\n","250 480 Loss: -1067388.434512\n","300 480 Loss: -1067674.238164\n","350 480 Loss: -1067651.941595\n","400 480 Loss: -1066290.388560\n","450 480 Loss: -1066318.493487\n","Epoch: 46, train loss: -1064474.8510, training accuracy 0.6946, dev set accuracy 0.5120\n","0 480 Loss: -1098703.500000\n","50 480 Loss: -1084514.240196\n","100 480 Loss: -1057596.619431\n","150 480 Loss: -1062158.853477\n","200 480 Loss: -1063223.496269\n","250 480 Loss: -1063725.996265\n","300 480 Loss: -1067338.139327\n","350 480 Loss: -1064512.117877\n","400 480 Loss: -1067461.090243\n","450 480 Loss: -1069440.006098\n","Epoch: 47, train loss: -1069254.3993, training accuracy 0.6926, dev set accuracy 0.5250\n","0 480 Loss: -980163.125000\n","50 480 Loss: -1097409.667892\n","100 480 Loss: -1077753.681931\n","150 480 Loss: -1075439.136589\n","200 480 Loss: -1075539.400808\n","250 480 Loss: -1075856.449950\n","300 480 Loss: -1077555.419643\n","350 480 Loss: -1075297.016382\n","400 480 Loss: -1075463.193111\n","450 480 Loss: -1077044.560837\n","Epoch: 48, train loss: -1075179.4086, training accuracy 0.7112, dev set accuracy 0.5250\n","0 480 Loss: -1085035.250000\n","50 480 Loss: -1056946.334559\n","100 480 Loss: -1065906.521040\n","150 480 Loss: -1070745.235099\n","200 480 Loss: -1073569.131219\n","250 480 Loss: -1075546.418078\n","300 480 Loss: -1074882.613164\n","350 480 Loss: -1074091.638355\n","400 480 Loss: -1074107.302525\n","450 480 Loss: -1074372.815687\n","Epoch: 49, train loss: -1077533.7699, training accuracy 0.7146, dev set accuracy 0.5070\n","0 480 Loss: -1249541.250000\n","50 480 Loss: -1077301.585784\n","100 480 Loss: -1070422.798886\n","150 480 Loss: -1086355.216060\n","200 480 Loss: -1092481.579602\n","250 480 Loss: -1087283.507968\n","300 480 Loss: -1084869.191030\n","350 480 Loss: -1085712.166311\n","400 480 Loss: -1083824.688591\n","450 480 Loss: -1079289.241962\n","Epoch: 50, train loss: -1079631.6624, training accuracy 0.7268, dev set accuracy 0.5140\n","0 480 Loss: -1091597.500000\n","50 480 Loss: -1065609.082108\n","100 480 Loss: -1076015.975866\n","150 480 Loss: -1070135.954056\n","200 480 Loss: -1076597.042600\n","250 480 Loss: -1075228.521912\n","300 480 Loss: -1075695.926910\n","350 480 Loss: -1078831.393340\n","400 480 Loss: -1080258.849127\n","450 480 Loss: -1082530.615715\n","Epoch: 51, train loss: -1081501.2306, training accuracy 0.7282, dev set accuracy 0.5040\n","0 480 Loss: -1187656.125000\n","50 480 Loss: -1081495.495098\n","100 480 Loss: -1078693.201733\n","150 480 Loss: -1079385.887417\n","200 480 Loss: -1086321.827114\n","250 480 Loss: -1085008.927789\n","300 480 Loss: -1088011.286130\n","350 480 Loss: -1089502.903668\n","400 480 Loss: -1090812.435786\n","450 480 Loss: -1089261.165327\n","Epoch: 52, train loss: -1088781.5195, training accuracy 0.7452, dev set accuracy 0.5150\n","0 480 Loss: -1043167.375000\n","50 480 Loss: -1139952.519608\n","100 480 Loss: -1116303.000619\n","150 480 Loss: -1100639.993791\n","200 480 Loss: -1093011.563744\n","250 480 Loss: -1093229.071215\n","300 480 Loss: -1093916.493355\n","350 480 Loss: -1090806.047009\n","400 480 Loss: -1090521.502026\n","450 480 Loss: -1090503.368210\n","Epoch: 53, train loss: -1090098.7469, training accuracy 0.7506, dev set accuracy 0.4975\n","0 480 Loss: -996891.000000\n","50 480 Loss: -1092646.221814\n","100 480 Loss: -1097039.084777\n","150 480 Loss: -1093609.072434\n","200 480 Loss: -1094612.044776\n","250 480 Loss: -1098083.723108\n","300 480 Loss: -1092374.546096\n","350 480 Loss: -1093152.637286\n","400 480 Loss: -1092272.118921\n","450 480 Loss: -1091463.018570\n","Epoch: 54, train loss: -1092964.9320, training accuracy 0.7654, dev set accuracy 0.5235\n","0 480 Loss: -943731.125000\n","50 480 Loss: -1108270.449755\n","100 480 Loss: -1098910.394183\n","150 480 Loss: -1098234.513659\n","200 480 Loss: -1101557.008706\n","250 480 Loss: -1102016.709163\n","300 480 Loss: -1103495.084718\n","350 480 Loss: -1099648.077813\n","400 480 Loss: -1099627.112999\n","450 480 Loss: -1097622.558343\n","Epoch: 55, train loss: -1097806.7615, training accuracy 0.7702, dev set accuracy 0.5095\n","0 480 Loss: -992237.875000\n","50 480 Loss: -1084067.887255\n","100 480 Loss: -1101841.074876\n","150 480 Loss: -1104325.945364\n","200 480 Loss: -1099182.632152\n","250 480 Loss: -1101212.390438\n","300 480 Loss: -1102318.410922\n","350 480 Loss: -1100977.319266\n","400 480 Loss: -1100128.178304\n","450 480 Loss: -1099791.479213\n","Epoch: 56, train loss: -1098645.1518, training accuracy 0.7662, dev set accuracy 0.5240\n","0 480 Loss: -1381441.000000\n","50 480 Loss: -1116271.732843\n","100 480 Loss: -1098746.017327\n","150 480 Loss: -1104485.684603\n","200 480 Loss: -1103030.523321\n","250 480 Loss: -1102032.645667\n","300 480 Loss: -1106151.789037\n","350 480 Loss: -1105063.423255\n","400 480 Loss: -1104106.348036\n","450 480 Loss: -1104431.757483\n","Epoch: 57, train loss: -1103192.7956, training accuracy 0.7814, dev set accuracy 0.5350\n","0 480 Loss: -966995.062500\n","50 480 Loss: -1085653.767157\n","100 480 Loss: -1100319.476485\n","150 480 Loss: -1094909.099752\n","200 480 Loss: -1098221.980100\n","250 480 Loss: -1102143.372012\n","300 480 Loss: -1100310.866279\n","350 480 Loss: -1102535.618234\n","400 480 Loss: -1100939.530393\n","450 480 Loss: -1102790.101025\n","Epoch: 58, train loss: -1101188.2738, training accuracy 0.7890, dev set accuracy 0.5150\n","0 480 Loss: -1269846.875000\n","50 480 Loss: -1092720.666667\n","100 480 Loss: -1101986.163985\n","150 480 Loss: -1105569.884520\n","200 480 Loss: -1101544.439055\n","250 480 Loss: -1099057.633964\n","300 480 Loss: -1104283.822882\n","350 480 Loss: -1104705.885150\n","400 480 Loss: -1107166.785380\n","450 480 Loss: -1107319.149806\n","Epoch: 59, train loss: -1106644.8115, training accuracy 0.7996, dev set accuracy 0.5015\n","0 480 Loss: -1101760.000000\n","50 480 Loss: -1107767.861520\n","100 480 Loss: -1112373.570545\n","150 480 Loss: -1111732.336921\n","200 480 Loss: -1112897.547264\n","250 480 Loss: -1110506.086902\n","300 480 Loss: -1106371.955980\n","350 480 Loss: -1107542.579238\n","400 480 Loss: -1105965.356453\n","450 480 Loss: -1106068.455931\n","Epoch: 60, train loss: -1105953.1267, training accuracy 0.7958, dev set accuracy 0.5265\n","0 480 Loss: -1140582.875000\n","50 480 Loss: -1099270.618873\n","100 480 Loss: -1100765.224010\n","150 480 Loss: -1108888.596440\n","200 480 Loss: -1113267.926306\n","250 480 Loss: -1112585.518924\n","300 480 Loss: -1108713.559385\n","350 480 Loss: -1109819.175926\n","400 480 Loss: -1107823.642924\n","450 480 Loss: -1107663.526608\n","Epoch: 61, train loss: -1109051.6460, training accuracy 0.8116, dev set accuracy 0.5395\n","0 480 Loss: -1003045.250000\n","50 480 Loss: -1099065.216912\n","100 480 Loss: -1099380.683168\n","150 480 Loss: -1103537.622930\n","200 480 Loss: -1106275.283271\n","250 480 Loss: -1105654.054034\n","300 480 Loss: -1108342.043397\n","350 480 Loss: -1109611.772792\n","400 480 Loss: -1110271.035069\n","450 480 Loss: -1109605.981569\n","Epoch: 62, train loss: -1109879.6710, training accuracy 0.8170, dev set accuracy 0.5320\n","0 480 Loss: -966840.000000\n","50 480 Loss: -1130610.335784\n","100 480 Loss: -1119601.535891\n","150 480 Loss: -1114507.668460\n","200 480 Loss: -1116796.245025\n","250 480 Loss: -1116120.007968\n","300 480 Loss: -1114854.234842\n","350 480 Loss: -1112657.079060\n","400 480 Loss: -1115827.008416\n","450 480 Loss: -1116779.240715\n","Epoch: 63, train loss: -1116453.3534, training accuracy 0.8274, dev set accuracy 0.5245\n","0 480 Loss: -1076927.125000\n","50 480 Loss: -1111723.654412\n","100 480 Loss: -1111712.818688\n","150 480 Loss: -1111946.995033\n","200 480 Loss: -1117064.237873\n","250 480 Loss: -1120481.374751\n","300 480 Loss: -1120384.269934\n","350 480 Loss: -1118381.868412\n","400 480 Loss: -1118467.070605\n","450 480 Loss: -1117129.124307\n","Epoch: 64, train loss: -1117472.6410, training accuracy 0.8322, dev set accuracy 0.5240\n","0 480 Loss: -978907.375000\n","50 480 Loss: -1104456.935049\n","100 480 Loss: -1116495.357054\n","150 480 Loss: -1125701.283113\n","200 480 Loss: -1124758.928172\n","250 480 Loss: -1116630.077440\n","300 480 Loss: -1115187.309593\n","350 480 Loss: -1114223.243590\n","400 480 Loss: -1116159.164121\n","450 480 Loss: -1116742.997090\n","Epoch: 65, train loss: -1116162.2740, training accuracy 0.8324, dev set accuracy 0.4960\n","0 480 Loss: -1177039.500000\n","50 480 Loss: -1127820.019608\n","100 480 Loss: -1132218.571782\n","150 480 Loss: -1122483.022351\n","200 480 Loss: -1124113.982898\n","250 480 Loss: -1118040.025896\n","300 480 Loss: -1116546.048380\n","350 480 Loss: -1116908.719551\n","400 480 Loss: -1116596.170979\n","450 480 Loss: -1118127.439163\n","Epoch: 66, train loss: -1117467.5181, training accuracy 0.8330, dev set accuracy 0.5265\n","0 480 Loss: -1094008.750000\n","50 480 Loss: -1132971.312500\n","100 480 Loss: -1121115.208540\n","150 480 Loss: -1120526.540977\n","200 480 Loss: -1123743.365672\n","250 480 Loss: -1125454.543576\n","300 480 Loss: -1122032.313953\n","350 480 Loss: -1120917.567842\n","400 480 Loss: -1123196.605050\n","450 480 Loss: -1122203.423780\n","Epoch: 67, train loss: -1121575.1126, training accuracy 0.8424, dev set accuracy 0.5220\n","0 480 Loss: -1000620.125000\n","50 480 Loss: -1102555.973039\n","100 480 Loss: -1111262.987624\n","150 480 Loss: -1113525.004553\n","200 480 Loss: -1117997.487873\n","250 480 Loss: -1125202.316484\n","300 480 Loss: -1123479.700581\n","350 480 Loss: -1120734.423967\n","400 480 Loss: -1122627.403834\n","450 480 Loss: -1121655.559313\n","Epoch: 68, train loss: -1122441.8055, training accuracy 0.8584, dev set accuracy 0.4995\n","0 480 Loss: -1361693.750000\n","50 480 Loss: -1131365.844363\n","100 480 Loss: -1118250.767946\n","150 480 Loss: -1124726.793460\n","200 480 Loss: -1128239.352923\n","250 480 Loss: -1130280.990040\n","300 480 Loss: -1129953.641819\n","350 480 Loss: -1126127.389601\n","400 480 Loss: -1124895.150249\n","450 480 Loss: -1123068.285061\n","Epoch: 69, train loss: -1122189.6461, training accuracy 0.8516, dev set accuracy 0.5265\n","0 480 Loss: -1208148.500000\n","50 480 Loss: -1112930.742647\n","100 480 Loss: -1116129.366337\n","150 480 Loss: -1118284.049255\n","200 480 Loss: -1121225.443719\n","250 480 Loss: -1122781.365538\n","300 480 Loss: -1127168.383098\n","350 480 Loss: -1125179.619836\n","400 480 Loss: -1124420.013716\n","450 480 Loss: -1124814.595621\n","Epoch: 70, train loss: -1124299.6232, training accuracy 0.8632, dev set accuracy 0.5230\n","0 480 Loss: -1006961.375000\n","50 480 Loss: -1126557.761029\n","100 480 Loss: -1126476.506807\n","150 480 Loss: -1121390.715646\n","200 480 Loss: -1122853.986629\n","250 480 Loss: -1130318.801793\n","300 480 Loss: -1129185.073920\n","350 480 Loss: -1131952.004808\n","400 480 Loss: -1129264.853647\n","450 480 Loss: -1129117.028409\n","Epoch: 71, train loss: -1127363.8866, training accuracy 0.8608, dev set accuracy 0.5130\n","0 480 Loss: -1098329.000000\n","50 480 Loss: -1140537.172794\n","100 480 Loss: -1144326.622525\n","150 480 Loss: -1145671.486341\n","200 480 Loss: -1136212.311256\n","250 480 Loss: -1134209.723357\n","300 480 Loss: -1130530.574751\n","350 480 Loss: -1128656.192130\n","400 480 Loss: -1129917.285380\n","450 480 Loss: -1128206.934590\n","Epoch: 72, train loss: -1128611.8740, training accuracy 0.8658, dev set accuracy 0.5200\n","0 480 Loss: -1023814.750000\n","50 480 Loss: -1142622.924020\n","100 480 Loss: -1133588.364480\n","150 480 Loss: -1131025.932947\n","200 480 Loss: -1138496.632152\n","250 480 Loss: -1135602.638197\n","300 480 Loss: -1135678.502699\n","350 480 Loss: -1138151.417557\n","400 480 Loss: -1136151.089776\n","450 480 Loss: -1134034.366131\n","Epoch: 73, train loss: -1132102.2087, training accuracy 0.8776, dev set accuracy 0.5225\n","0 480 Loss: -977145.875000\n","50 480 Loss: -1137849.946078\n","100 480 Loss: -1143784.737005\n","150 480 Loss: -1128685.656457\n","200 480 Loss: -1128408.069963\n","250 480 Loss: -1130399.656624\n","300 480 Loss: -1126863.107973\n","350 480 Loss: -1131286.820513\n","400 480 Loss: -1135593.166459\n","450 480 Loss: -1133200.841325\n","Epoch: 74, train loss: -1133787.0974, training accuracy 0.8838, dev set accuracy 0.5305\n","0 480 Loss: -1108704.125000\n","50 480 Loss: -1163758.590686\n","100 480 Loss: -1144250.346535\n","150 480 Loss: -1136490.133692\n","200 480 Loss: -1130993.852923\n","250 480 Loss: -1138085.508715\n","300 480 Loss: -1133298.260382\n","350 480 Loss: -1132545.858440\n","400 480 Loss: -1133734.980206\n","450 480 Loss: -1133985.495011\n","Epoch: 75, train loss: -1134125.0505, training accuracy 0.8884, dev set accuracy 0.5425\n","0 480 Loss: -1061936.000000\n","50 480 Loss: -1137468.573529\n","100 480 Loss: -1137492.590965\n","150 480 Loss: -1135418.735513\n","200 480 Loss: -1130516.618781\n","250 480 Loss: -1133161.417331\n","300 480 Loss: -1133931.790905\n","350 480 Loss: -1135637.385506\n","400 480 Loss: -1136578.098815\n","450 480 Loss: -1136884.144817\n","Epoch: 76, train loss: -1136871.2910, training accuracy 0.8882, dev set accuracy 0.5315\n","0 480 Loss: -1218093.250000\n","50 480 Loss: -1149300.325980\n","100 480 Loss: -1138307.601485\n","150 480 Loss: -1137862.052566\n","200 480 Loss: -1137206.846704\n","250 480 Loss: -1144095.545070\n","300 480 Loss: -1137876.414659\n","350 480 Loss: -1137780.189459\n","400 480 Loss: -1137552.596166\n","450 480 Loss: -1137234.420593\n","Epoch: 77, train loss: -1138227.3113, training accuracy 0.8854, dev set accuracy 0.5280\n","0 480 Loss: -1072949.125000\n","50 480 Loss: -1128994.504902\n","100 480 Loss: -1138218.599629\n","150 480 Loss: -1137881.413493\n","200 480 Loss: -1134913.327736\n","250 480 Loss: -1137307.710906\n","300 480 Loss: -1139265.555233\n","350 480 Loss: -1140192.795940\n","400 480 Loss: -1138942.166615\n","450 480 Loss: -1136998.299058\n","Epoch: 78, train loss: -1134600.1702, training accuracy 0.8964, dev set accuracy 0.5325\n","0 480 Loss: -1180741.000000\n","50 480 Loss: -1150938.028186\n","100 480 Loss: -1146781.734530\n","150 480 Loss: -1147083.496275\n","200 480 Loss: -1140594.895211\n","250 480 Loss: -1140365.016185\n","300 480 Loss: -1140263.936254\n","350 480 Loss: -1140933.509793\n","400 480 Loss: -1140021.187812\n","450 480 Loss: -1138742.961475\n","Epoch: 79, train loss: -1138478.8992, training accuracy 0.9084, dev set accuracy 0.5345\n","0 480 Loss: -921538.875000\n","50 480 Loss: -1142066.533088\n","100 480 Loss: -1155215.211634\n","150 480 Loss: -1146348.022765\n","200 480 Loss: -1142072.472326\n","250 480 Loss: -1145002.421315\n","300 480 Loss: -1143991.477782\n","350 480 Loss: -1142393.379986\n","400 480 Loss: -1143664.362687\n","450 480 Loss: -1143108.499030\n","Epoch: 80, train loss: -1143159.1427, training accuracy 0.8976, dev set accuracy 0.5250\n","0 480 Loss: -940000.250000\n","50 480 Loss: -1145263.534314\n","100 480 Loss: -1142048.387376\n","150 480 Loss: -1145692.778974\n","200 480 Loss: -1144722.281716\n","250 480 Loss: -1141446.726345\n","300 480 Loss: -1141363.941030\n","350 480 Loss: -1142650.398682\n","400 480 Loss: -1143662.425499\n","450 480 Loss: -1143099.306957\n","Epoch: 81, train loss: -1141751.6602, training accuracy 0.9064, dev set accuracy 0.5355\n","0 480 Loss: -1165740.250000\n","50 480 Loss: -1150611.122549\n","100 480 Loss: -1156226.640470\n","150 480 Loss: -1147145.276490\n","200 480 Loss: -1155367.248134\n","250 480 Loss: -1155199.739542\n","300 480 Loss: -1152318.868978\n","350 480 Loss: -1148795.862001\n","400 480 Loss: -1143941.574657\n","450 480 Loss: -1143768.104213\n","Epoch: 82, train loss: -1143825.0020, training accuracy 0.9020, dev set accuracy 0.5190\n","0 480 Loss: -1235707.750000\n","50 480 Loss: -1155542.848039\n","100 480 Loss: -1146266.689356\n","150 480 Loss: -1146585.364238\n","200 480 Loss: -1149034.810012\n","250 480 Loss: -1141318.431524\n","300 480 Loss: -1139907.510382\n","350 480 Loss: -1144050.273504\n","400 480 Loss: -1142398.917082\n","450 480 Loss: -1142914.157844\n","Epoch: 83, train loss: -1143569.0699, training accuracy 0.9094, dev set accuracy 0.5205\n","0 480 Loss: -917935.312500\n","50 480 Loss: -1167749.906863\n","100 480 Loss: -1159060.574257\n","150 480 Loss: -1151588.314983\n","200 480 Loss: -1147876.467662\n","250 480 Loss: -1147782.038347\n","300 480 Loss: -1147003.086379\n","350 480 Loss: -1143370.678775\n","400 480 Loss: -1143434.376870\n","450 480 Loss: -1144576.321092\n","Epoch: 84, train loss: -1145647.7339, training accuracy 0.9110, dev set accuracy 0.5255\n","0 480 Loss: -1232598.000000\n","50 480 Loss: -1140781.814951\n","100 480 Loss: -1144719.623762\n","150 480 Loss: -1144004.942053\n","200 480 Loss: -1145885.334577\n","250 480 Loss: -1147438.686006\n","300 480 Loss: -1145230.144726\n","350 480 Loss: -1146292.134972\n","400 480 Loss: -1149677.685786\n","450 480 Loss: -1149342.398559\n","Epoch: 85, train loss: -1149183.2134, training accuracy 0.9140, dev set accuracy 0.5280\n","0 480 Loss: -1227630.125000\n","50 480 Loss: -1124316.280637\n","100 480 Loss: -1129175.154084\n","150 480 Loss: -1137629.176738\n","200 480 Loss: -1139834.951803\n","250 480 Loss: -1141144.249502\n","300 480 Loss: -1147152.336586\n","350 480 Loss: -1147093.397436\n","400 480 Loss: -1148622.010131\n","450 480 Loss: -1150295.415604\n","Epoch: 86, train loss: -1148108.1135, training accuracy 0.9206, dev set accuracy 0.5325\n","0 480 Loss: -1264069.875000\n","50 480 Loss: -1150708.794118\n","100 480 Loss: -1147057.842822\n","150 480 Loss: -1147485.259106\n","200 480 Loss: -1149603.455846\n","250 480 Loss: -1148916.704183\n","300 480 Loss: -1146560.001246\n","350 480 Loss: -1147865.177350\n","400 480 Loss: -1146980.040212\n","450 480 Loss: -1147701.884146\n","Epoch: 87, train loss: -1149442.4927, training accuracy 0.9178, dev set accuracy 0.5365\n","0 480 Loss: -1218002.125000\n","50 480 Loss: -1142512.194853\n","100 480 Loss: -1146278.818688\n","150 480 Loss: -1143680.666805\n","200 480 Loss: -1139480.788868\n","250 480 Loss: -1144369.185010\n","300 480 Loss: -1148049.145141\n","350 480 Loss: -1148712.552707\n","400 480 Loss: -1148452.888560\n","450 480 Loss: -1147778.276885\n","Epoch: 88, train loss: -1149966.2741, training accuracy 0.9194, dev set accuracy 0.5325\n","0 480 Loss: -1090868.000000\n","50 480 Loss: -1134279.658088\n","100 480 Loss: -1149335.448639\n","150 480 Loss: -1146794.170530\n","200 480 Loss: -1148559.403607\n","250 480 Loss: -1151736.731325\n","300 480 Loss: -1154264.697259\n","350 480 Loss: -1153511.337785\n","400 480 Loss: -1154863.196384\n","450 480 Loss: -1152394.226857\n","Epoch: 89, train loss: -1152524.8591, training accuracy 0.9268, dev set accuracy 0.5225\n","0 480 Loss: -1217133.750000\n","50 480 Loss: -1168920.256127\n","100 480 Loss: -1158316.229579\n","150 480 Loss: -1158222.665149\n","200 480 Loss: -1158559.418532\n","250 480 Loss: -1155953.455428\n","300 480 Loss: -1154909.118563\n","350 480 Loss: -1156426.400819\n","400 480 Loss: -1157208.809071\n","450 480 Loss: -1154624.786724\n","Epoch: 90, train loss: -1154488.3582, training accuracy 0.9280, dev set accuracy 0.5170\n","0 480 Loss: -985798.000000\n","50 480 Loss: -1118761.096814\n","100 480 Loss: -1123155.810644\n","150 480 Loss: -1141361.905629\n","200 480 Loss: -1144526.253731\n","250 480 Loss: -1144633.674801\n","300 480 Loss: -1146836.332226\n","350 480 Loss: -1147212.723291\n","400 480 Loss: -1150257.417550\n","450 480 Loss: -1149484.868764\n","Epoch: 91, train loss: -1151331.7699, training accuracy 0.9238, dev set accuracy 0.5135\n","0 480 Loss: -1153912.750000\n","50 480 Loss: -1138538.285539\n","100 480 Loss: -1155206.140470\n","150 480 Loss: -1149031.724752\n","200 480 Loss: -1150975.965174\n","250 480 Loss: -1157901.285110\n","300 480 Loss: -1152886.800042\n","350 480 Loss: -1154804.464209\n","400 480 Loss: -1154338.037562\n","450 480 Loss: -1155307.725610\n","Epoch: 92, train loss: -1154811.5382, training accuracy 0.9260, dev set accuracy 0.5445\n","0 480 Loss: -1076902.625000\n","50 480 Loss: -1165722.261029\n","100 480 Loss: -1171178.215347\n","150 480 Loss: -1162651.565397\n","200 480 Loss: -1158982.456779\n","250 480 Loss: -1161363.646663\n","300 480 Loss: -1161013.240033\n","350 480 Loss: -1159760.141560\n","400 480 Loss: -1159332.558915\n","450 480 Loss: -1159702.155765\n","Epoch: 93, train loss: -1158261.5448, training accuracy 0.9322, dev set accuracy 0.5380\n","0 480 Loss: -1071117.250000\n","50 480 Loss: -1152207.329657\n","100 480 Loss: -1166964.750619\n","150 480 Loss: -1161029.953642\n","200 480 Loss: -1160281.228234\n","250 480 Loss: -1162321.609313\n","300 480 Loss: -1159096.846761\n","350 480 Loss: -1160600.021902\n","400 480 Loss: -1156284.957450\n","450 480 Loss: -1157052.770371\n","Epoch: 94, train loss: -1156169.7507, training accuracy 0.9286, dev set accuracy 0.5390\n","0 480 Loss: -1001890.125000\n","50 480 Loss: -1142008.791667\n","100 480 Loss: -1148599.789604\n","150 480 Loss: -1158365.116722\n","200 480 Loss: -1155637.207400\n","250 480 Loss: -1156955.167829\n","300 480 Loss: -1157767.128322\n","350 480 Loss: -1158866.476496\n","400 480 Loss: -1162567.172382\n","450 480 Loss: -1161402.560698\n","Epoch: 95, train loss: -1161628.8815, training accuracy 0.9408, dev set accuracy 0.5465\n","0 480 Loss: -1087314.375000\n","50 480 Loss: -1171048.213235\n","100 480 Loss: -1158477.985767\n","150 480 Loss: -1156713.126656\n","200 480 Loss: -1153494.284204\n","250 480 Loss: -1152860.509711\n","300 480 Loss: -1155140.589286\n","350 480 Loss: -1160016.855413\n","400 480 Loss: -1156759.957918\n","450 480 Loss: -1158097.257483\n","Epoch: 96, train loss: -1158032.1611, training accuracy 0.9452, dev set accuracy 0.5250\n","0 480 Loss: -1240161.500000\n","50 480 Loss: -1148143.035539\n","100 480 Loss: -1155181.558168\n","150 480 Loss: -1156532.564570\n","200 480 Loss: -1168230.352612\n","250 480 Loss: -1171743.624751\n","300 480 Loss: -1167705.844269\n","350 480 Loss: -1167707.797187\n","400 480 Loss: -1165381.533042\n","450 480 Loss: -1163705.852273\n","Epoch: 97, train loss: -1162673.4733, training accuracy 0.9422, dev set accuracy 0.5390\n","0 480 Loss: -1124376.000000\n","50 480 Loss: -1162831.617647\n","100 480 Loss: -1173702.616955\n","150 480 Loss: -1168375.561672\n","200 480 Loss: -1161092.496269\n","250 480 Loss: -1162309.150896\n","300 480 Loss: -1161532.016611\n","350 480 Loss: -1161042.118234\n","400 480 Loss: -1161677.159913\n","450 480 Loss: -1160997.443875\n","Epoch: 98, train loss: -1160602.9668, training accuracy 0.9384, dev set accuracy 0.5425\n","0 480 Loss: -1062304.000000\n","50 480 Loss: -1154176.441176\n","100 480 Loss: -1148895.499381\n","150 480 Loss: -1157095.677152\n","200 480 Loss: -1159669.999689\n","250 480 Loss: -1163049.526892\n","300 480 Loss: -1161826.481520\n","350 480 Loss: -1161456.761574\n","400 480 Loss: -1162110.314838\n","450 480 Loss: -1166013.970621\n","Epoch: 99, train loss: -1163832.0319, training accuracy 0.9438, dev set accuracy 0.5145\n","0 480 Loss: -1029262.375000\n","50 480 Loss: -1173596.884804\n","100 480 Loss: -1177604.383045\n","150 480 Loss: -1170694.658113\n","200 480 Loss: -1168934.117226\n","250 480 Loss: -1165611.689990\n","300 480 Loss: -1162449.369186\n","350 480 Loss: -1165011.099537\n","400 480 Loss: -1162439.524158\n","450 480 Loss: -1162678.879019\n","Epoch: 100, train loss: -1163280.9806, training accuracy 0.9398, dev set accuracy 0.5380\n"]}],"source":["#fit M2 model\n","#labeled_data_len is the number of labeled data in train+dev set: 450+1050\n","m2.fit(train_loader,dev_loader,100,alpha,labeled_data_len = 7000)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83u-X-fGtqae","outputId":"abfeb912-7b9d-4dd4-bb62-c66aa52bb63d","executionInfo":{"status":"ok","timestamp":1651701305395,"user_tz":240,"elapsed":283,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5465"]},"metadata":{},"execution_count":31}],"source":["#best dev set accuracy \n","m2.model.best_dev_accuracy"]},{"cell_type":"markdown","metadata":{"id":"ftuQtN-8tqag"},"source":["# Baseline Model:\n","### Only using the labeled data for supervised learning"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"kjbvy8iGtqah","executionInfo":{"status":"ok","timestamp":1651701305399,"user_tz":240,"elapsed":262,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#use the same dev set as M2\n","dev_ind_b = dev_ind\n","#training data is the same 1050 labeled data as M2\n","train_ind_b = (np.setdiff1d(labeled_ind, dev_ind))"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"4Yd9GQq9tqai","executionInfo":{"status":"ok","timestamp":1651701305403,"user_tz":240,"elapsed":264,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"757b1bfb-4283-4b71-d348-34f036afc8b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2000, 5000)"]},"metadata":{},"execution_count":33}],"source":["len(dev_ind_b),len(train_ind_b)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"oAn2wW7ntqal","executionInfo":{"status":"ok","timestamp":1651701305425,"user_tz":240,"elapsed":266,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#prepare dataloader for pytroch\n","images_train_b = [data[i] for i in train_ind_b]\n","trainset_b = TorchInputData(images_train_b, labels[train_ind_b])\n","train_loader_b = tud.DataLoader(trainset_b, batch_size=50, shuffle=True)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"p0RqfXV7tqam","executionInfo":{"status":"ok","timestamp":1651701305427,"user_tz":240,"elapsed":267,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["images_dev_b = [data[i] for i in dev_ind_b]\n","devset_b = TorchInputData(images_dev_b, labels[dev_ind_b])\n","dev_loader_b = tud.DataLoader(devset_b, batch_size=50, shuffle=True)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"S2jusPJOtqao","executionInfo":{"status":"ok","timestamp":1651701305428,"user_tz":240,"elapsed":267,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["from dcganbaseline_cnn_stl10_cuda import BaselineConvNetdc"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"yGm1JqNWtqaq","executionInfo":{"status":"ok","timestamp":1651701305429,"user_tz":240,"elapsed":268,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["baseline = BaselineConvNetdc(96, path = \"baseline_stl10_100epoch_5.pth\")"]},{"cell_type":"code","source":["from baseline_cnn_stl10_cuda import BaselineConvNet"],"metadata":{"id":"Qsi2itlg5Hzw","executionInfo":{"status":"ok","timestamp":1651701305431,"user_tz":240,"elapsed":269,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["baseline2 = BaselineConvNet(96, path = \"baseline2_stl10_100epoch_5.pth\")"],"metadata":{"id":"ei-Hj3Z85M8M","executionInfo":{"status":"ok","timestamp":1651701305438,"user_tz":240,"elapsed":272,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cnAGDX6mtFsz"},"source":["### Structure of the baseline model: same as the classifier in the M2 model"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"9NhcNx4VtFsz","executionInfo":{"status":"ok","timestamp":1651701305440,"user_tz":240,"elapsed":273,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc07b00d-4273-4e7f-a120-65b589b6a05d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TwoLayerConvNet(\n","  (net): Sequential(\n","    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n","    (1): Dropout(p=0.2, inplace=False)\n","    (2): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): LeakyReLU(negative_slope=0.01)\n","    (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): LeakyReLU(negative_slope=0.01)\n","    (6): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (7): LeakyReLU(negative_slope=0.01)\n","    (8): Dropout(p=0.5, inplace=False)\n","    (9): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (10): LeakyReLU(negative_slope=0.01)\n","    (11): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): LeakyReLU(negative_slope=0.01)\n","    (13): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (14): LeakyReLU(negative_slope=0.01)\n","    (15): Dropout(p=0.5, inplace=False)\n","    (16): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))\n","    (17): LeakyReLU(negative_slope=0.01)\n","    (18): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (19): LeakyReLU(negative_slope=0.01)\n","    (20): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (21): LeakyReLU(negative_slope=0.01)\n","    (22): AdaptiveAvgPool2d(output_size=1)\n","    (23): Flatten(start_dim=1, end_dim=-1)\n","  )\n","  (fc): Linear(in_features=192, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":40}],"source":["baseline.model"]},{"cell_type":"code","source":["baseline2.model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YC484Wb5Qat","executionInfo":{"status":"ok","timestamp":1651701305442,"user_tz":240,"elapsed":254,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"5d0ae4c7-6acc-40e9-bb15-42d70eec5070"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TwoLayerConvNet(\n","  (conv1_drop): Dropout2d(p=0.2, inplace=False)\n","  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2_drop): Dropout2d(p=0.2, inplace=False)\n","  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n","  (fc1): Linear(in_features=2880, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["baseline2.fit(train_loader_b,dev_loader_b)\n","baseline2.train(50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrZKhkf05UG6","executionInfo":{"status":"ok","timestamp":1651701337993,"user_tz":240,"elapsed":32787,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"289c85e9-9d77-489f-f417-625c2e19be5b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/5000 (0%)]\tLoss: 2.762003\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Dev set: Average loss: 2.0497, Accuracy: 535/2000 (27%)\n","\n","Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.031864\n","\n","Dev set: Average loss: 1.8191, Accuracy: 704/2000 (35%)\n","\n","Train Epoch: 2 [0/5000 (0%)]\tLoss: 1.624905\n","\n","Dev set: Average loss: 1.7482, Accuracy: 742/2000 (37%)\n","\n","Train Epoch: 3 [0/5000 (0%)]\tLoss: 1.677052\n","\n","Dev set: Average loss: 1.6751, Accuracy: 766/2000 (38%)\n","\n","Train Epoch: 4 [0/5000 (0%)]\tLoss: 1.606902\n","\n","Dev set: Average loss: 1.6519, Accuracy: 780/2000 (39%)\n","\n","Train Epoch: 5 [0/5000 (0%)]\tLoss: 1.526712\n","\n","Dev set: Average loss: 1.6095, Accuracy: 851/2000 (43%)\n","\n","Train Epoch: 6 [0/5000 (0%)]\tLoss: 1.430116\n","\n","Dev set: Average loss: 1.6232, Accuracy: 848/2000 (42%)\n","\n","Train Epoch: 7 [0/5000 (0%)]\tLoss: 1.260201\n","\n","Dev set: Average loss: 1.5718, Accuracy: 880/2000 (44%)\n","\n","Train Epoch: 8 [0/5000 (0%)]\tLoss: 1.328674\n","\n","Dev set: Average loss: 1.5771, Accuracy: 875/2000 (44%)\n","\n","Train Epoch: 9 [0/5000 (0%)]\tLoss: 1.054727\n","\n","Dev set: Average loss: 1.6059, Accuracy: 861/2000 (43%)\n","\n","Train Epoch: 10 [0/5000 (0%)]\tLoss: 1.167699\n","\n","Dev set: Average loss: 1.5735, Accuracy: 916/2000 (46%)\n","\n","Train Epoch: 11 [0/5000 (0%)]\tLoss: 0.942344\n","\n","Dev set: Average loss: 1.5908, Accuracy: 897/2000 (45%)\n","\n","Train Epoch: 12 [0/5000 (0%)]\tLoss: 1.108445\n","\n","Dev set: Average loss: 1.6606, Accuracy: 893/2000 (45%)\n","\n","Train Epoch: 13 [0/5000 (0%)]\tLoss: 0.877964\n","\n","Dev set: Average loss: 1.7173, Accuracy: 875/2000 (44%)\n","\n","Train Epoch: 14 [0/5000 (0%)]\tLoss: 0.756322\n","\n","Dev set: Average loss: 1.7769, Accuracy: 890/2000 (44%)\n","\n","Train Epoch: 15 [0/5000 (0%)]\tLoss: 0.701138\n","\n","Dev set: Average loss: 1.7280, Accuracy: 862/2000 (43%)\n","\n","Train Epoch: 16 [0/5000 (0%)]\tLoss: 0.626911\n","\n","Dev set: Average loss: 1.8194, Accuracy: 905/2000 (45%)\n","\n","Train Epoch: 17 [0/5000 (0%)]\tLoss: 0.680679\n","\n","Dev set: Average loss: 1.8857, Accuracy: 906/2000 (45%)\n","\n","Train Epoch: 18 [0/5000 (0%)]\tLoss: 0.831469\n","\n","Dev set: Average loss: 2.0833, Accuracy: 858/2000 (43%)\n","\n","Train Epoch: 19 [0/5000 (0%)]\tLoss: 0.760732\n","\n","Dev set: Average loss: 1.9852, Accuracy: 891/2000 (45%)\n","\n","Train Epoch: 20 [0/5000 (0%)]\tLoss: 0.436313\n","\n","Dev set: Average loss: 2.1496, Accuracy: 910/2000 (46%)\n","\n","Train Epoch: 21 [0/5000 (0%)]\tLoss: 0.521510\n","\n","Dev set: Average loss: 2.2532, Accuracy: 884/2000 (44%)\n","\n","Train Epoch: 22 [0/5000 (0%)]\tLoss: 0.360043\n","\n","Dev set: Average loss: 2.3586, Accuracy: 910/2000 (46%)\n","\n","Train Epoch: 23 [0/5000 (0%)]\tLoss: 0.383104\n","\n","Dev set: Average loss: 2.5380, Accuracy: 883/2000 (44%)\n","\n","Train Epoch: 24 [0/5000 (0%)]\tLoss: 0.443893\n","\n","Dev set: Average loss: 2.5716, Accuracy: 871/2000 (44%)\n","\n","Train Epoch: 25 [0/5000 (0%)]\tLoss: 0.225943\n","\n","Dev set: Average loss: 2.7012, Accuracy: 877/2000 (44%)\n","\n","Train Epoch: 26 [0/5000 (0%)]\tLoss: 0.130518\n","\n","Dev set: Average loss: 2.8116, Accuracy: 900/2000 (45%)\n","\n","Train Epoch: 27 [0/5000 (0%)]\tLoss: 0.143886\n","\n","Dev set: Average loss: 3.0512, Accuracy: 874/2000 (44%)\n","\n","Train Epoch: 28 [0/5000 (0%)]\tLoss: 0.066120\n","\n","Dev set: Average loss: 3.1135, Accuracy: 906/2000 (45%)\n","\n","Train Epoch: 29 [0/5000 (0%)]\tLoss: 0.196712\n","\n","Dev set: Average loss: 3.2576, Accuracy: 862/2000 (43%)\n","\n","Train Epoch: 30 [0/5000 (0%)]\tLoss: 0.263502\n","\n","Dev set: Average loss: 3.6164, Accuracy: 850/2000 (42%)\n","\n","Train Epoch: 31 [0/5000 (0%)]\tLoss: 0.150178\n","\n","Dev set: Average loss: 3.4094, Accuracy: 920/2000 (46%)\n","\n","Train Epoch: 32 [0/5000 (0%)]\tLoss: 0.094978\n","\n","Dev set: Average loss: 3.5470, Accuracy: 861/2000 (43%)\n","\n","Train Epoch: 33 [0/5000 (0%)]\tLoss: 0.201097\n","\n","Dev set: Average loss: 3.8644, Accuracy: 889/2000 (44%)\n","\n","Train Epoch: 34 [0/5000 (0%)]\tLoss: 0.031047\n","\n","Dev set: Average loss: 3.8189, Accuracy: 889/2000 (44%)\n","\n","Train Epoch: 35 [0/5000 (0%)]\tLoss: 0.029089\n","\n","Dev set: Average loss: 3.9763, Accuracy: 900/2000 (45%)\n","\n","Train Epoch: 36 [0/5000 (0%)]\tLoss: 0.014565\n","\n","Dev set: Average loss: 4.1562, Accuracy: 926/2000 (46%)\n","\n","Train Epoch: 37 [0/5000 (0%)]\tLoss: 0.009425\n","\n","Dev set: Average loss: 4.3226, Accuracy: 912/2000 (46%)\n","\n","Train Epoch: 38 [0/5000 (0%)]\tLoss: 0.030163\n","\n","Dev set: Average loss: 4.2976, Accuracy: 907/2000 (45%)\n","\n","Train Epoch: 39 [0/5000 (0%)]\tLoss: 0.012995\n","\n","Dev set: Average loss: 4.3742, Accuracy: 909/2000 (45%)\n","\n","Train Epoch: 40 [0/5000 (0%)]\tLoss: 0.009822\n","\n","Dev set: Average loss: 4.4485, Accuracy: 914/2000 (46%)\n","\n","Train Epoch: 41 [0/5000 (0%)]\tLoss: 0.006699\n","\n","Dev set: Average loss: 4.5648, Accuracy: 919/2000 (46%)\n","\n","Train Epoch: 42 [0/5000 (0%)]\tLoss: 0.002607\n","\n","Dev set: Average loss: 4.6484, Accuracy: 932/2000 (47%)\n","\n","Train Epoch: 43 [0/5000 (0%)]\tLoss: 0.002094\n","\n","Dev set: Average loss: 4.7299, Accuracy: 915/2000 (46%)\n","\n","Train Epoch: 44 [0/5000 (0%)]\tLoss: 0.002986\n","\n","Dev set: Average loss: 4.7881, Accuracy: 914/2000 (46%)\n","\n","Train Epoch: 45 [0/5000 (0%)]\tLoss: 0.002986\n","\n","Dev set: Average loss: 4.8489, Accuracy: 916/2000 (46%)\n","\n","Train Epoch: 46 [0/5000 (0%)]\tLoss: 0.001047\n","\n","Dev set: Average loss: 4.9132, Accuracy: 918/2000 (46%)\n","\n","Train Epoch: 47 [0/5000 (0%)]\tLoss: 0.002007\n","\n","Dev set: Average loss: 4.9471, Accuracy: 911/2000 (46%)\n","\n","Train Epoch: 48 [0/5000 (0%)]\tLoss: 0.002152\n","\n","Dev set: Average loss: 5.0057, Accuracy: 917/2000 (46%)\n","\n","Train Epoch: 49 [0/5000 (0%)]\tLoss: 0.001018\n","\n","Dev set: Average loss: 5.0488, Accuracy: 920/2000 (46%)\n","\n"]}]},{"cell_type":"code","execution_count":43,"metadata":{"id":"tqRBjNGTtFsz","executionInfo":{"status":"ok","timestamp":1651701421611,"user_tz":240,"elapsed":83633,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9155a86c-472f-433e-db7f-820556068224"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/5000 (0%)]\tLoss: 2.299841\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Dev set: Average loss: 2.0842, Accuracy: 374/2000 (19%)\n","\n","Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.128844\n","\n","Dev set: Average loss: 1.9530, Accuracy: 505/2000 (25%)\n","\n","Train Epoch: 2 [0/5000 (0%)]\tLoss: 1.857945\n","\n","Dev set: Average loss: 1.8792, Accuracy: 545/2000 (27%)\n","\n","Train Epoch: 3 [0/5000 (0%)]\tLoss: 1.837338\n","\n","Dev set: Average loss: 1.8460, Accuracy: 537/2000 (27%)\n","\n","Train Epoch: 4 [0/5000 (0%)]\tLoss: 1.837660\n","\n","Dev set: Average loss: 1.8270, Accuracy: 557/2000 (28%)\n","\n","Train Epoch: 5 [0/5000 (0%)]\tLoss: 1.849494\n","\n","Dev set: Average loss: 1.7820, Accuracy: 595/2000 (30%)\n","\n","Train Epoch: 6 [0/5000 (0%)]\tLoss: 1.758944\n","\n","Dev set: Average loss: 1.7918, Accuracy: 582/2000 (29%)\n","\n","Train Epoch: 7 [0/5000 (0%)]\tLoss: 1.775547\n","\n","Dev set: Average loss: 1.6904, Accuracy: 647/2000 (32%)\n","\n","Train Epoch: 8 [0/5000 (0%)]\tLoss: 1.570917\n","\n","Dev set: Average loss: 1.6774, Accuracy: 724/2000 (36%)\n","\n","Train Epoch: 9 [0/5000 (0%)]\tLoss: 1.613821\n","\n","Dev set: Average loss: 1.6501, Accuracy: 720/2000 (36%)\n","\n","Train Epoch: 10 [0/5000 (0%)]\tLoss: 1.746087\n","\n","Dev set: Average loss: 1.6817, Accuracy: 689/2000 (34%)\n","\n","Train Epoch: 11 [0/5000 (0%)]\tLoss: 1.788726\n","\n","Dev set: Average loss: 1.6451, Accuracy: 701/2000 (35%)\n","\n","Train Epoch: 12 [0/5000 (0%)]\tLoss: 1.744843\n","\n","Dev set: Average loss: 1.6180, Accuracy: 754/2000 (38%)\n","\n","Train Epoch: 13 [0/5000 (0%)]\tLoss: 1.555268\n","\n","Dev set: Average loss: 1.6286, Accuracy: 781/2000 (39%)\n","\n","Train Epoch: 14 [0/5000 (0%)]\tLoss: 1.520490\n","\n","Dev set: Average loss: 1.6160, Accuracy: 747/2000 (37%)\n","\n","Train Epoch: 15 [0/5000 (0%)]\tLoss: 1.486205\n","\n","Dev set: Average loss: 1.5602, Accuracy: 810/2000 (40%)\n","\n","Train Epoch: 16 [0/5000 (0%)]\tLoss: 1.270722\n","\n","Dev set: Average loss: 1.5709, Accuracy: 820/2000 (41%)\n","\n","Train Epoch: 17 [0/5000 (0%)]\tLoss: 1.338449\n","\n","Dev set: Average loss: 1.5642, Accuracy: 836/2000 (42%)\n","\n","Train Epoch: 18 [0/5000 (0%)]\tLoss: 1.484959\n","\n","Dev set: Average loss: 1.5229, Accuracy: 870/2000 (44%)\n","\n","Train Epoch: 19 [0/5000 (0%)]\tLoss: 1.274805\n","\n","Dev set: Average loss: 1.5608, Accuracy: 845/2000 (42%)\n","\n","Train Epoch: 20 [0/5000 (0%)]\tLoss: 1.491662\n","\n","Dev set: Average loss: 1.5202, Accuracy: 889/2000 (44%)\n","\n","Train Epoch: 21 [0/5000 (0%)]\tLoss: 1.406061\n","\n","Dev set: Average loss: 1.5174, Accuracy: 878/2000 (44%)\n","\n","Train Epoch: 22 [0/5000 (0%)]\tLoss: 1.259504\n","\n","Dev set: Average loss: 1.4825, Accuracy: 865/2000 (43%)\n","\n","Train Epoch: 23 [0/5000 (0%)]\tLoss: 1.337889\n","\n","Dev set: Average loss: 1.4813, Accuracy: 897/2000 (45%)\n","\n","Train Epoch: 24 [0/5000 (0%)]\tLoss: 1.376635\n","\n","Dev set: Average loss: 1.4433, Accuracy: 928/2000 (46%)\n","\n","Train Epoch: 25 [0/5000 (0%)]\tLoss: 1.215519\n","\n","Dev set: Average loss: 1.4238, Accuracy: 953/2000 (48%)\n","\n","Train Epoch: 26 [0/5000 (0%)]\tLoss: 1.140915\n","\n","Dev set: Average loss: 1.5248, Accuracy: 889/2000 (44%)\n","\n","Train Epoch: 27 [0/5000 (0%)]\tLoss: 1.095704\n","\n","Dev set: Average loss: 1.4286, Accuracy: 944/2000 (47%)\n","\n","Train Epoch: 28 [0/5000 (0%)]\tLoss: 1.475318\n","\n","Dev set: Average loss: 1.3637, Accuracy: 1034/2000 (52%)\n","\n","Train Epoch: 29 [0/5000 (0%)]\tLoss: 0.870712\n","\n","Dev set: Average loss: 1.3537, Accuracy: 1037/2000 (52%)\n","\n","Train Epoch: 30 [0/5000 (0%)]\tLoss: 1.048652\n","\n","Dev set: Average loss: 1.3832, Accuracy: 1027/2000 (51%)\n","\n","Train Epoch: 31 [0/5000 (0%)]\tLoss: 0.830329\n","\n","Dev set: Average loss: 1.3593, Accuracy: 1040/2000 (52%)\n","\n","Train Epoch: 32 [0/5000 (0%)]\tLoss: 0.809330\n","\n","Dev set: Average loss: 1.3541, Accuracy: 1077/2000 (54%)\n","\n","Train Epoch: 33 [0/5000 (0%)]\tLoss: 0.854352\n","\n","Dev set: Average loss: 1.3527, Accuracy: 1066/2000 (53%)\n","\n","Train Epoch: 34 [0/5000 (0%)]\tLoss: 0.800945\n","\n","Dev set: Average loss: 1.4367, Accuracy: 1033/2000 (52%)\n","\n","Train Epoch: 35 [0/5000 (0%)]\tLoss: 0.825052\n","\n","Dev set: Average loss: 1.4540, Accuracy: 1045/2000 (52%)\n","\n","Train Epoch: 36 [0/5000 (0%)]\tLoss: 0.811913\n","\n","Dev set: Average loss: 1.3495, Accuracy: 1064/2000 (53%)\n","\n","Train Epoch: 37 [0/5000 (0%)]\tLoss: 0.719094\n","\n","Dev set: Average loss: 1.5013, Accuracy: 1067/2000 (53%)\n","\n","Train Epoch: 38 [0/5000 (0%)]\tLoss: 0.780407\n","\n","Dev set: Average loss: 1.4250, Accuracy: 1061/2000 (53%)\n","\n","Train Epoch: 39 [0/5000 (0%)]\tLoss: 0.658418\n","\n","Dev set: Average loss: 1.4343, Accuracy: 1067/2000 (53%)\n","\n","Train Epoch: 40 [0/5000 (0%)]\tLoss: 0.851724\n","\n","Dev set: Average loss: 1.4290, Accuracy: 1073/2000 (54%)\n","\n","Train Epoch: 41 [0/5000 (0%)]\tLoss: 0.768559\n","\n","Dev set: Average loss: 1.6978, Accuracy: 1028/2000 (51%)\n","\n","Train Epoch: 42 [0/5000 (0%)]\tLoss: 0.965495\n","\n","Dev set: Average loss: 1.4745, Accuracy: 1099/2000 (55%)\n","\n","Train Epoch: 43 [0/5000 (0%)]\tLoss: 0.439986\n","\n","Dev set: Average loss: 1.5183, Accuracy: 1063/2000 (53%)\n","\n","Train Epoch: 44 [0/5000 (0%)]\tLoss: 0.656791\n","\n","Dev set: Average loss: 1.6002, Accuracy: 1072/2000 (54%)\n","\n","Train Epoch: 45 [0/5000 (0%)]\tLoss: 0.550935\n","\n","Dev set: Average loss: 1.5758, Accuracy: 1082/2000 (54%)\n","\n","Train Epoch: 46 [0/5000 (0%)]\tLoss: 0.443829\n","\n","Dev set: Average loss: 1.7523, Accuracy: 1080/2000 (54%)\n","\n","Train Epoch: 47 [0/5000 (0%)]\tLoss: 0.409547\n","\n","Dev set: Average loss: 1.7041, Accuracy: 1080/2000 (54%)\n","\n","Train Epoch: 48 [0/5000 (0%)]\tLoss: 0.279699\n","\n","Dev set: Average loss: 1.8159, Accuracy: 1121/2000 (56%)\n","\n","Train Epoch: 49 [0/5000 (0%)]\tLoss: 0.406376\n","\n","Dev set: Average loss: 1.7635, Accuracy: 1085/2000 (54%)\n","\n","Train Epoch: 50 [0/5000 (0%)]\tLoss: 0.566631\n","\n","Dev set: Average loss: 1.8904, Accuracy: 1066/2000 (53%)\n","\n","Train Epoch: 51 [0/5000 (0%)]\tLoss: 0.415501\n","\n","Dev set: Average loss: 1.9886, Accuracy: 1001/2000 (50%)\n","\n","Train Epoch: 52 [0/5000 (0%)]\tLoss: 0.662198\n","\n","Dev set: Average loss: 2.1086, Accuracy: 1042/2000 (52%)\n","\n","Train Epoch: 53 [0/5000 (0%)]\tLoss: 0.475475\n","\n","Dev set: Average loss: 1.9694, Accuracy: 1046/2000 (52%)\n","\n","Train Epoch: 54 [0/5000 (0%)]\tLoss: 0.297460\n","\n","Dev set: Average loss: 2.0054, Accuracy: 1111/2000 (56%)\n","\n","Train Epoch: 55 [0/5000 (0%)]\tLoss: 0.297318\n","\n","Dev set: Average loss: 2.3225, Accuracy: 1081/2000 (54%)\n","\n","Train Epoch: 56 [0/5000 (0%)]\tLoss: 0.252984\n","\n","Dev set: Average loss: 2.0993, Accuracy: 1101/2000 (55%)\n","\n","Train Epoch: 57 [0/5000 (0%)]\tLoss: 0.294886\n","\n","Dev set: Average loss: 2.4590, Accuracy: 1039/2000 (52%)\n","\n","Train Epoch: 58 [0/5000 (0%)]\tLoss: 0.295695\n","\n","Dev set: Average loss: 2.5189, Accuracy: 1105/2000 (55%)\n","\n","Train Epoch: 59 [0/5000 (0%)]\tLoss: 0.335381\n","\n","Dev set: Average loss: 2.2038, Accuracy: 1044/2000 (52%)\n","\n"]}],"source":["baseline.fit(train_loader_b,dev_loader_b)\n","baseline.train(60)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"BODrszuktqat","executionInfo":{"status":"ok","timestamp":1651701421612,"user_tz":240,"elapsed":49,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae31a1c7-6a45-414c-f73d-081ef493ccce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5605"]},"metadata":{},"execution_count":44}],"source":["#best dev set accuracy \n","baseline.model.best_dev_accuracy"]},{"cell_type":"code","source":["baseline2.model.best_dev_accuracy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8DmhlrAHTE-","executionInfo":{"status":"ok","timestamp":1651701421613,"user_tz":240,"elapsed":39,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"18e799e6-9596-4f60-9de8-254ffdc0b496"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.466"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"9dQtIEBhtqau"},"source":["# Test Set Performance: \n","### The M2 model successfully increase the accuracy of the classifier"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"Zl0AOKQytqav","executionInfo":{"status":"ok","timestamp":1651701421613,"user_tz":240,"elapsed":26,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}}},"outputs":[],"source":["#The testset dataloader\n","testset_loader = torch.utils.data.DataLoader(test, batch_size=500, shuffle=True, num_workers=0)"]},{"cell_type":"code","source":["conf_b, acc_b = baseline.test(testset_loader,path = \"baseline_stl10_100epoch_5.pth\",return_confusion_matrix = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GEutUdLjG8wE","executionInfo":{"status":"ok","timestamp":1651701427166,"user_tz":240,"elapsed":5578,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"outputId":"b8fac407-fa2f-4efc-c221-746a4b885416"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Accuracy: 5486/10000 (55%)\n","\n"]}]},{"cell_type":"code","execution_count":48,"metadata":{"id":"LNHiD7kDtqaw","executionInfo":{"status":"ok","timestamp":1651701432234,"user_tz":240,"elapsed":5079,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ed1bd31-8130-4ec3-a5c3-c60c9b5fb1d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Accuracy: 4641/10000 (46%)\n","\n"]}],"source":["conf_b2, acc_b2 = baseline2.test(testset_loader,path = \"baseline2_stl10_100epoch_5.pth\",return_confusion_matrix = True)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"SJPvWwAUtqax","executionInfo":{"status":"ok","timestamp":1651701437497,"user_tz":240,"elapsed":5275,"user":{"displayName":"Atul Zacharias","userId":"07392057183854948695"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6bc334d0-473b-46cb-ba54-86af918c6e73"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Accuracy: 5405/10000 (54%)\n","\n"]}],"source":["conf, acc = m2.test(testset_loader,path = \"m2_stl10_0.1_50epoch_5.pth\",return_confusion_matrix = True)"]}],"metadata":{"colab":{"name":"pytorchVAEcifar10.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}